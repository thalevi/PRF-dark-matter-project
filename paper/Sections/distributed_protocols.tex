%!TEX root = ../main.tex
\newpage
\section{Distributed Protocols}
\label{sec:distributed_protocols}
We now describe efficient protocols to compute our candidate constructions in several interesting distributed settings. This section is structured as follows. First, in Section~\ref{subsec:protocol_overview}, we provide a technical overview for our overall protocol design. This includes computation protocols for each of our circuit gates as well as a generic way to compose them to obtain fully distributed protocols in the preprocessing model for all our constructions. Section~\ref{subsec:distributed_protocol} quantifies this approach by providing concrete communication and preprocessing costs for distributed evaluations for our constructions. In Section~\ref{subsec:3party_protocol}, for our \ttwPRF construction, we provide a 3-party protocol that does not require any preprocessing and is secure against one passive corruption. Finally, in Section~\ref{subsec:oprf_protocol}, we provide two OPRF protocols for our \ttwPRF construction in the preprocessing model. All provided protocols are for the semi-honest setting.
\iffull\else In many cases, we defer the full details to Appendix~\ref{appendix:protocols}.\fi

\subsection{Technical Overview}
\label{subsec:protocol_overview}
Recall that all our constructions can be succinctly represented using five basic gates. The main strategy now will be to evaluate each of these gates in a distributed manner. These gate evaluation subprotocols can then be easily composed to evaluate the  candidate constructions. 

We begin with distributed protocols to evaluate each of the five gates. Abstractly, the goal of a gate protocol is to convert shares of the inputs to shares of the outputs (or shares of the masked output). To make our formalism cleaner, the gate protocols, by themselves, will involve no communication. Instead, they can additionally take in masked versions of the inputs, and possibly some additional correlated randomness. When composing gate protocols, whenever a masked input is needed, the parties will exchange their local shares to publicly reveal the masked value. This choice also prevents redoing the same communication when the masked value is already available from earlier gate evaluations.


\iffull
\paragraph{Protocol notation and considerations.}
For a protocol $\prot$, we use the notation $\prot(a_1, \dots, a_k \mid b_1, \dots, b_l)$ to denote that the values $a_1, \dots, a_k$ are provided publicly to all parties in the protocol, while the values $b_1, \dots, b_l$ are secret shared among the parties. When $\party_i$ knows the values $(a_1, \dots, a_k)$, and has shares $\sharei{b_1}, \dots, \share{b_l})$, we use the notation $\prot(a_1, \dots, a_k \mid \sharei{b_1}, \dots, \sharei{b_l})$ to denote that $\party_i$ runs the protocol with its local inputs. 

Given public values $a_1, \dots, a_k$, it is straightforward for the protocol parties to compute a sharing $\share{f(a_1, \dots, a_k)}$ for a function $f$ (for example, $\party_1$ computes the function as its share, and all other parties set their share to $0$).
\else

\subsubsection{Distributed Computation of Circuit Gates}
We provide detailed (local) protocols to compute each circuit gate in this section. The description of inputs (including shared correlated randomness) and outputs for each gate protocol is also summarized in Table~\ref{table:gate_protocol_summary}. 
\iffull\else Protocols for the $\LMap$ and $\Add$ gates directly follow from the homomorphic properties of additive secret sharing, while the protocol for the $\BLMap$ gate is essentially a generalization of Beaver's multiplication triples~\cite{boyle2019-fss-preprocess,beaver1991-triples}. In this section, we provide our novel protocols for the $\Convert_{(2,3)}$ and $\Convert_{(3,2)}$ gates and defer the details for the other gates to Appendix~\ref{appendix:protocol_gates}.
\fi
\begin{table}[t!]
\lncsresize{
\centering
{
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|c|c|c|c|}

\hline
Protocol & \makecell{Public \\ Inputs} & \makecell{Shared \\ Inputs} & \makecell{Shared \\ Correlated Randomness} & \makecell{Output Shares \\ (over base group $\mathbb{G}$)} \\
\hline
$\prot_{\LMap}^{\mat{A},p}$ & $\mat{A}$ & $x$ & - & $y = \mat{A}x$ (over $\Z_p$)\\
\hline
$\prot_{\Add}^{p}$ & & $x, x'$ & - & $y = x + x'$ (over $\Z_p$)\\
\hline
$\prot_{\BLMap}^p$ & $\hat{\mat{K}}, \hat{x}$ & - & $\tilde{\mat{K}},\tilde{x}, \tilde{\mat{K}}\tilde{x}$ & $y = \mat{K}x$ (over $\Z_p$)\\
\hline
$\prot_{\Convert}^{(2,3)}$ & $\hat{x}$ (over $\Z_2$) & - & $r = \tilde{x}$ (over $\Z_3$) & $x^* = x$ (over $\Z_3$) \\
\hline
$\prot_{\Convert}^{(3,2)}$ & $\hat{x}$ (over $\Z_3$) & - & \makecell{$u = \tilde{x} \bmod 2$ (over $\Z_2$) \\ $v = (\tilde{x} + \textbf{1} \bmod 3) \bmod 2$ (over $\Z_2$)} & $x^* = x \bmod 2$ (over $\Z_2$) \\
\hline
\end{tabular}
}
}
\caption{Summary of input, output, and randomness for the circuit gate protocols.
% \greg{Change ``over base group'' to ``over group''?}
}
\label{table:gate_protocol_summary}
\end{table}

\iffull

\paragraph{Linear gate protocol $\prot_\LMap^{\mat{A}, p}$.}
The linear gate is the easiest to evaluate, and follows from the standard linear homomorphism of additive secret sharing.

\begin{itemize}
  \item \textbf{Functionality}: Each party is provided with the matrix $\mat{A}$ and shares of the input $x$ (over $\Z_p$). The goal is to compute shares of the output $y = \mat{A}x$.

  \item \textbf{Preprocessing}: None required.

  \item \textbf{Protocol details}:
  For the protocol $\prot_\LMap^{\mat{A}, p}(\mat{A} \mid x)$, each party $\party_i$ computes its output share as $\sharei{y} = \mat{A}\sharei{x}$. Note that this works because $\mat{A}x = \sum_{\party_i \in \parties} \mat{A}\sharei{x}$ as a direct consequence of the linear homomorphism of additive shares.
\end{itemize}

\paragraph{Addition gate protocol $\prot_\Add^{p}$.}
The addition modulo $p$ gate is also easy to evaluate. Given shares of $x, x'$ over $\Z_p$, for the protocol each party $\party_i$ can locally compute its share of $x+x'$ as $\sharei{x} + \sharei{x'} \bmod p$. This directly follows from the additive homomorphism of additive shares. 

\paragraph{Bilinear gate protocol $\prot_\BLMap^p$.}
The bilinear gate protocol is essentially a generalization of Beaver's multiplication triples~\cite{boyle2019-fss-preprocess,beaver1991-triples} that computes the multiplication of two shared inputs. For Beaver's protocol, to compute a sharing of $ab$ given shares of $a$ and $b$ (all sharings are over a ring $\mathcal{R}$), the protocol parties are provided shares of a randomly sampled triple of the form $(\tilde{a},\tilde{b},\tilde{a}\tilde{b})$ in the preprocessing stage. Beaver's protocol first reconstructs the masked inputs $\hat{a}$ and $\hat{b}$ after which local computation is enough to produce shares of the output. For our bilinear gate protocol, we assume that  all parties are already provided with the masked inputs (to move the communication outside of the gate protocol), along with correlated randomness similar to a Beaver triple. 

\begin{itemize}
  \item \textbf{Functionality}: 
  Abstractly, the goal of the bilinear gate protocol is to compute shares of the output $y = \mat{K}x$ given shares of both inputs $\mat{K}$ and $x$. For our purpose however, the masked inputs will have already been constructed beforehand, i.e., each party is provided with $\hat{\mat{K}}$ and $\hat{x}$ publicly, along with shares of correlated randomness similar to a Beaver triple (see below).

  \item \textbf{Preprocessing}: Each party is provided shares of $\tilde{\mat{K}}, \tilde{x}$, and $\tilde{\mat{K}}\tilde{x}$ as correlated randomness.

  \item \textbf{Protocol details}: For the protocol $\prot_\BLMap^p(\hat{\mat{K}},\hat{x}\mid \tilde{\mat{K}}, \tilde{x}, \tilde{\mat{K}}\tilde{x})$, each party $\party_i$ computes its share of $\hat{y}$ as:
  \[
    \sharei{\hat{y}} = \sharei{\hat{\mat{K}}\hat{x}} - \hat{\mat{K}}\sharei{\tilde{x}} - \sharei{\tilde{\mat{K}}}\hat{x} + \sharei{\tilde{\mat{K}}\tilde{x}}
  \]

  \noindent \textit{Correctness}. Note that this works since:
  \begin{align*}
  \sum_{\party_i \in \parties} \sharei{\hat{y}} &= \hat{\mat{K}}\hat{x} - \hat{\mat{K}}\tilde{x} - \tilde{\mat{K}}\hat{x} + \tilde{\mat{K}}\tilde{x} \\
  &= (\mat{K} + \tilde{\mat{K}})x - \tilde{\mat{K}}(x + \tilde{x}) + \tilde{\mat{K}}\tilde{x} \\
  &= \mat{K}x
  \end{align*}
\end{itemize}
Since the output of the bilinear gate will usually feed into a conversion gate which requires the input to be already masked, as an optimization, we can have the bilinear gate itself compute shares of the masked output, i.e., $\hat{y} = \mat{K}x + \tilde{y}$. This can be done by providing the correlated randomness $\tilde{\mat{K}}\tilde{x} + \tilde{y}$ instead of $\tilde{\mat{K}}\tilde{x}$. The upshot of this optimization is that one fewer piece of correlated randomness will be required.
\fi
\paragraph{$\Z_2 \to \Z_3$ conversion protocol $\prot_\Convert^{(2,3)}$.}

\begin{itemize}
  \item \textbf{Functionality}: Abstractly, the goal of the $\Z_2 \to \Z_3$ conversion protocol is to convert a sharing of $x$ over $\Z_2$ to a sharing of the same $x^* = x$, but now over $\Z_3$. For our purpose, the parties will be provided the masked input $\hat{x} = x \oplus \tilde{x}$ (i.e., masking is over $\Z_2$) directly along with correlated randomness that shares $\tilde{x}$ over $\Z_3$.

  \item \textbf{Preprocessing}: Each party is also provided with shares of the mask $r = \tilde{x}$ over $\Z_3$ as correlated randomness.

  \item \textbf{Protocol details}: For the protocol $\prot_\Convert^{(2,3)}(\hat{x} \mid r)$, each party proceeds as follows:
  \[
  \sharei{x^*} = \sharei{\hat{x}} + \sharei{r} + (\hat{x} \odot \sharei{r}) \quad \bmod 3
  \]
where $\odot$ denotes the Hammard (component-wise) product modulo 3. Here, addition is also done over $\Z_3$.

\noindent \textit{Correctness.} To see why this works, suppose that $\hat{x} \in \Z_2^l$. Consider any position $j \in [l]$, and denote by using a subscript $j$, the $j^\thtext$ position in a vector. Note that now, the position $j$ of the output can be written as:
\[
    \sharei{x^*}_j = \sharei{\hat{x}}_j + \sharei{r}_j + (\hat{x}\sharei{r}_j\bmod 3) \quad \bmod 3
\]
Consider two cases:
\begin{itemize}
\item If $\hat{x}_j = 0$, then $\tilde{x}_j = x_j$. Therefore, $\sum_{\party_i \in \parties} \sharei{x^*}_j = 0 + \tilde{x}_j = x_j$.

\item If $\hat{x}_j = 1$, then $x_j = 1 - \tilde{x}_j$. Therefore, $\sum_{\party_i \in \parties} \sharei{x^*}_j = 1 + 2\tilde{x}_j \bmod 3$. If $\tilde{x}_j = 0$, this evaluates to $1 = x_j$, while if $\tilde{x}_j = 1$, it evaluates to $0 = 1 - \tilde{x}_j = x_j$
\end{itemize}
In other words, in all cases, each component of the sum ($\bmod~3$) of shares $\sharei{x^*}$ is the same as the corresponding component of $x$. Therefore, 
\[
\sum_{\party_i \in \parties} \sharei{x^*} (\bmod~3) = x
\]
will hold.
\end{itemize}


\paragraph{$\Z_3 \to \Z_2$ conversion protocol $\prot_\Convert^{(3,2)}$.}

\begin{itemize}
  \item \textbf{Functionality}: Abstractly, the goal of the protocol is to convert a sharing of $x$ over $\Z_3$ to a sharing of $x^* = x \bmod~2$ over $\Z_2$. For our purpose, the parties will be provided with the masked input $\hat{x} = x + \tilde{x} \bmod~3$ directly, along with correlated randomness over $\Z_3$ (see below).

  \item \textbf{Preprocessing}: Each party is also given shares (over $\Z_2$) of two vectors: $u = \tilde{x} \bmod 2$ and $v = (\tilde{x} + \textbf{1} \bmod 3) \bmod 2$ as correlated randomness.


  \item \textbf{Protocol details}: For the protocol $\prot_\Convert^{(3,2)}(\hat{x} \mid u, v)$, each party computes its share of $x^*$ as follows: For each position $j \in [l]$,
\[
\sharei{x^*}_j = 
\begin{cases*}
       1 - \sharei{u}_j - \sharei{v}_j  & \quad if $\hat{x}_j = 0$ \\
       \sharei{v}_j & \quad if $\hat{x}_j = 1$ \\
       \sharei{u}_j & \quad if $\hat{x}_j = 2$
\end{cases*}
\]
\textit{Correctness.} To see why this works, consider three cases:
\begin{itemize}
\item If $\hat{x}_j = 0$, then $\sum_{\party_i \in \parties} \sharei{x^*}_j \bmod 2 = 1 - u_j - v_j$. This evaluates to $1$ only when $\tilde{x}_j = 2$, and is exactly the case when $x_j$ is also 1.

\item $\hat{x}_j = 1$, then $\sum_{\party_i \in \parties} \sharei{x^*}_j \bmod 2 = v_j = (\tilde{x}_j + 1 \bmod 3) \bmod 2)$. This evaluates to $1$ only when $\tilde{x}_j = 0$, and is exactly the case when $x_j$ is also 1.

\item $\hat{x}_j = 2$, then $\sum_{\party_i \in \parties} \sharei{x^*}_j \bmod 2 = u_j$. This evaluates to $1$ only when $\tilde{x}_j = 1$, and is exactly the case when $x_j$ is also 1.
\end{itemize}
Consequently, $\sum_{\party_i \in \parties} \sharei{x^*} \bmod 2 = x \bmod 2$ holds.
\end{itemize}


%-------------------------------%

\subsubsection{Composing Gate Protocols}
We now describe a general technique to evaluate circuit composed of the previously specified gates in a distributed fashion. We provide details for the semi-honest fully distributed setting (with preprocessing), where all inputs are secret shared between all parties initially. This can also be thought of as a toolbox for constructing efficient distributed protocols for other constructions similar to ours. While the technique will also work for other settings (e.g., OPRF, public input), the concrete communication costs will be worse than more specially designed protocols. For these settings, we will provide more efficient protocols than provided by this general technique.
\iffull\else
We provide only the basic description and discuss the communication and preprocessing cost, as well as optimizations in Appendix~\ref{appendix:protocol_generic}.
\fi

% \greg{Does it make sense to say that this very general composition protocol can
% allow one to easily make protocols for variants of our primitives? ``MPC
% toolbox for alternating moduli primitives'' or similar}

\paragraph{Composition protocol.} Consider a circuit $C$ (Definition~\ref{def:computation_circuit}) with input space $\Gin = \prod \Gin_i$. To evaluate $C$ with input $(x_1, \dots, x_l) \in \Gin$, in the fully distributed setting, all parties are given additive shares for each $x_i$. Now, the distributed evaluation of $C$ proceeds as follows:
\begin{itemize}
  
  \item All vertices at the same depth in $C$ are evaluated simultaneously, starting from the source vertices that contain the inputs of the computation. 

  \item The evaluation of a (non-source) vertex in the graph of $C$ is done by each party running the corresponding gate protocol locally on their share of the inputs. 

  \item For an edge $(V_a, V_b)$, suppose that the output of $V_a$ is used as one of the inputs of $V_b$. If the gate protocol corresponding to $\mathcal{G}_V$ requires this input to be masked (e.g., the bilinear gate protocol), then before evaluating $V_b$, each party first masks its share of the output. Now, all parties simultaneously reveal their shares to publicly reveal the masked value.   The masking values are provided to the parties in the preprocessing phase. The same value also need not be masked multiple times if it is required for multiple gates.

  \item The required output shares of the distributed evaluation are given by the evaluation of the sink vertices in the circuit.
\end{itemize}

\iffull
\paragraph{Communication cost.}
Since the gate protocols themselves are locally computable, the communication cost during a distributed evaluation of a circuit comes solely from the public reconstructions of masked values required for gate protocols. For example, before feeding the output $x$ of a $\LMap^{\mat{A}}_2$ gate into a $\Convert_{(2,3)}$ gate, in the distributed evaluation, all parties will first mask their shares of $x$ to obtain shares of $\hat{x}$. Then, the parties will exchange messages to reconstruct the $\hat{x}$ value required for $\prot_\Convert^{(2,3)}$.

Consider $N$ parties taking part in the distributed evaluation. To reconstruct an $l$-bit value $\hat{x}$ that is additively shared among the parties, one of the following can be done.
\begin{itemize}
  \item Each party sends its share of $\hat{x}$ to each other party. Now, all parties can compute $\hat{x}$ locally. This requires only 1 online round but has a communication cost of $(N-1)l$ bits per party. Each party sends $N-1$ messages. The simplest case for this is when $n=2$, in which case, both parties can simultaneously exchange their shares, and add the two shares locally to reconstruct $\hat{x}$. This requires 1 online round, and has a communication cost of $1$ message and $l$ bits per party. 

  \item All parties can send their share to a designated party, say $\party_1$, who computes $\hat{x}$ and sends it back to everyone. This requires 2 rounds and has a communication cost of $(N-1)l$ bits for $\party_1$ and $l$ bits each for other parties. Here, $\party_1$ sends $N-1$ messages while all other parties send a single message.
\end{itemize}


\paragraph{Reducing round complexity.} It is also straightforward to parallelize the communication to reduce the number of rounds. For this, suppose that we call an edge $(V_a, V_b)$ \textit{communication-requiring} if the output of the protocol for $V_a$ needs to be masked before it is input into the protocol for $V_b$ (in other words, the gate protocol for $V_b$ requires a masked input). Now, define the communication-depth of a vertex $V$ as the maximum number of communication-requiring edges in any path from a source vertex to $V$. Now, instead of evaluating vertices with the same depth simultaneously, we will evaluate vertices with the same \textit{communication-depth} together before the next communication round. By doing so, we can reduce the total number of rounds to the maximum communication-depth.


\paragraph{Preprocessing cost.}
A na{\"i}ve technique to compute the preprocessing required is to add the preprocessing for each gate in the circuit as follows:

\begin{itemize}
\item The $\LMap$ and $\Add$ gates are computed locally and require no preprocessing.

\item Each $\BLMap_p$ gate requires a Beaver-style triple which provides masks for the two inputs and a multiplication of the two masks. Specifically, for $\BLMap_p(\mat{K}, x)$ where $\mat{K} \in \Z_p^{l_2 \times l_1}$ and $x \in \Z_p^{l_1}$, the preprocessed shares are of the form $(\tilde{\mat{K}}, \tilde{x}, \tilde{\mat{K}}\tilde{x})$. Consequently, when $\mat{K}$ is circulant, a total of $(2l_1 + l_2) \log_p$ bits needs to be provided as preprocessing to each party.

\item Each $\Convert_{(2,3)}$ gate requires shares of a random mask $\tilde{x}$ both over $\Z_2$ and $\Z_3$. In other words, for $x \in \Z_2^l$, it requires $l + \log_2{3} \cdot l$ bits of preprocessing per party.

\item Each $\Convert_{(3,2)}$ gate requires shares of a random mask $\tilde{x}$ (over $\Z_3$) as well as $u = \tilde{x}$ and $v = (\tilde{x} + \textbf{1} \bmod 3)\bmod 2$ (both over $\Z_2$). In other words, for $x \in \Z_3^l$, it requires $\log_2{3} \cdot l + 2l$ bits of preprocessing per party.
\end{itemize}

\paragraph{Compressing preprocessing required.}
We describe several optimizations to reduce the total cost of preprocessing. We assume here the presence of a trusted dealer to generate any correlations in the randomness. We note that some of the optimizations, while reducing the size of preprocessing, would be more complicated to generate if a dealer is not present.

\begin{itemize}

  \item (Reducing redundant preprocessing).
  A straightforward optimization is to not mask the same value twice. For example, if the same value $x$ is considered as input for both a $\BLMap$ gate and a $\Convert$ gate, the same mask $\tilde{x}$ can be used for both. 

  \item (Masking $\BLMap$ gate outputs.)
  The standard $\BLMap$ gate requires preprocessing of the form $(\tilde{\mat{K}}, \tilde{x}, \tilde{\mat{K}}\tilde{x})$. However, if the output of the $\BLMap$ gate is then later input to a gate that requires a masked input (e.g., a $\Convert$ gate or even another $\BLMap$ gate), the $\BLMap$ gate can directly mask its output by providing $\tilde{\mat{K}}\tilde{x} + \tilde{y}$ instead. If this is done, the parties will compute a sharing of $\hat{y} = \mat{K}x + \tilde{y}$ using the $\BLMap$ gate. This means that the parties can directly exchange their shares to reconstruct $\hat{y}$ without requiring more preprocessing to mask $y$.

  For both the $\Convert_{2,3}$ and $\Convert_{(3,2)}$ gates, if the masked version $\hat{x}$ of the input $x$ is already known to all parties, only $\log_2{3} \cdot l$ and $2l$ bits respectively of preprocessing are required per party. 

 
  \item (Compression using a PRG).
  Another standard technique for compressing the size of preprocessing is to use a PRG. Intuitively, each party is given a different PRG seed by the trusted dealer which they can use locally to generate their randomness. Only a single party has its shares given by the dealer to ensure that the randomness is appropriately correlated. 

  % For this, the dealer will first generate the randomness as usual. To share the randomness, instead of randomly sampling shares, the dealer (who knows the seeds of all parties) will compute the shares for all but one party (say $\party_1$) using the party's PRG seed. The share for $\party_1$ can now be set so that the shares form an sharing of the required randomness.

  % More specifically, for the $\BLMap$ gate, a dealer first samples a random triple $(\tilde{K}, \tilde{x}, \tilde{K}\tilde{x})$
\end{itemize}
\else
Abstractly, communication will only be needed before $\BLMap, \Convert_{(2,3)}$, and $\Convert_{(3,2)}$ gates to reconstruct the masked input. In terms of preprocessing, if PRG seeds are used for compression, then the computation for the $\BLMap_p^{k,l}, \Convert^l_{(2,3)}$, and $\Convert^l_{(3,2)}$ gates will require a preprocessing of $\log_2{p} \cdot k$ bis, $\log_2{3} \cdot l$ bits, and $2l$ bits respectively.
\fi

\subsection{Distributed Evaluation in the Preprocessing Model}
\label{subsec:distributed_protocol}
\iffull
Equipped with our technical overview, we now move to constructing distributed protocols (with preprocessing) for our candidate constructions. By distributed evaluation, we mean that all inputs are secret shared between all parties and the protocol provides parties with a sharing of the output. As a concrete example, we provide the complete details of a 2-party distributed evaluation protocol for our \ttwPRF candidate.
\else
As a concrete example, we provide the complete details of a 2-party distributed evaluation protocol for our \ttwPRF candidate. By distributed evaluation, we mean that all inputs are secret shared between all parties and the protocol provides parties with a sharing of the output. 
\fi
%Later, in Table~\ref{table:construction_costs}, for each our constructions, we provide the amount of preprocessed randomness required as well as the communication cost for the distributed protocol.

\subsubsection{$2$-Party Protocol for \ttwPRF.}
\label{subsec:2pc-wprf}
We detail a $2$-party semi-honest protocol for evaluating our \ttwPRF candidate (Construction~\ref{construction:23-central-wprf}). In this setting, two parties, denoted by $\party_1$ and $\party_2$ hold additive shares of a key $\mat{K} \in \Z_2^{m \times n}$, and an input $x \in \Z_2^n$. The goal is to compute an additive sharing of the wPRF output $y = \LMap^\mat{B}_3(\mat{K}x)$ where $\mat{B} \in \Z_3^{t \times m}$ is a publicly known matrix.


\paragraph{Preprocessing.}
Our protocol requires preprocessed randomness as follows. A dealer randomly samples masks $\tilde{\mat{K}}$ and $\tilde{x}$ for $\mat{K}$ and $x$ respectively. It also randomly samples $\tilde{w} \in \Z_2^m$ as mask for the intermediate output. Let $r \in \Z_3^m; r = \tilde{w}$ (viewed over $\Z_3$). The dealer creates additive sharings for $\tilde{\mat{K}}, \tilde{x}, \tilde{\mat{K}}\tilde{x}, \tilde{w}$, and $r$. Each $\party_{i\in \{1,2\}}$ is now provided $\sharei{\tilde{\mat{K}}}, \sharei{\tilde{x}}, \sharei{\tilde{\mat{K}}\tilde{x}}, \sharei{\tilde{w}}$, and $\sharei{r}$ as preprocessing.

\paragraph{Protocol details.}
The distributed protocol proceeds as follows:
\begin{itemize}
    \item Each party $\party_i$ computes masks their key and input shares as 
    \begin{align*}
    \sharei{\hat{\mat{K}}} &= \sharei{\mat{K}} + \sharei{\tilde{\mat{K}}} \\
    \sharei{\hat{x}} &= \sharei{x} + \sharei{\tilde{x}}
    \end{align*}
    using its given randomness. The shares are then exchanged simultaneously by both parties to reconstruct $\mat{\hat{K}}$ and $\hat{x}$.

    \item Each party $\party_i$ now locally runs $\prot_\BLMap^2 \left(\hat{\mat{K}}, \hat{x} \mid \sharei{\tilde{\mat{K}}}, \sharei{\tilde{x}}, \sharei{\tilde{\mat{K}}\tilde{x}}\right)$ and adds to it its share of $\tilde{w}$ to obtain its share (over $\Z_2$) of $\hat{w} = \mat{K}x + \tilde{w}$. The shares are then exchanged simultaneously by both parties to reconstruct $\hat{w}$.

    \item Each party $\party_i$ now locally runs $\prot_{\Convert}^{(2,3)}(\hat{w} \mid \sharei{r})$ to obtain its shares of $w^* = w$ (over $\Z_3$).

    \item Finally, each party $\party_i$ obtains its share of the final output $y$ (over $\Z_3$) by running $\prot_\LMap^{\mat{B}, 3}(\mat{B} \mid \sharei{w^*})$.
\end{itemize}



\paragraph{Cost analysis.}
The distributed protocol takes 2 communication rounds in total, with both parties sending a message in each round. When $\mat{K}$ is a circulant matrix (i.e., it can be represented by $n$ bits), each party communicates $2n$ bits in the first round and $m$ bits in the second round.

As preprocessing, each party also receives shares of $\tilde{\mat{K}}, \tilde{x}, \tilde{\mat{K}}\tilde{x}, \tilde{w}$ (over $\Z_2$) and $\tilde{r} = \tilde{w}$ (over $\Z_3$). This can also be optimized by providing shares of $\tilde{\mat{K}}\tilde{x} + \tilde{w}$ for the $\BLMap$ gate directly. In total, if circulant keys are used, the preprocessing cost per party is $2n + m + \log_2{3}\cdot m$ bits.

Furthermore, if each party is given a PRG seed, then they can use the PRG to compute their shares of $\tilde{\mat{K}}$ and $\tilde{x}$. In this case, the dealer only needs to provide $\party_1$ with its shares for $\tilde{\mat{K}}\tilde{x} + \tilde{w}$ and $r$. $\party_2$ can compute its shares for those values using its PRG seed and the dealer can use its knowledge of $\party_2$'s seed to appropriately set the shares for $\party_1$. Consequently, across both parties, only $m + \log_2{3} \cdot m$ bits of preprocessing is required apart from the PRG seeds. Short $\secparam$-bit seeds can be provided to each party beforehand and reused for multiple evaluations.

In Appendix~\ref{appendix:protocol_other_settings}, we detail a 1-round protocol in the public-input setting (i.e., when the input $x$ is public.)

\iffull
\subsubsection{Public-input setting}
It is also straightforward to use the same generic technique to construct distributed protocols in the public-input setting. For keyed primitives, in public-input setting, the key is secret shared between the parties but the input is publicly known. The goal of the protocol is for the parties to compute shares of the output.

One useful optimization is that in the public-input setting, a $\BLMap$ gate where the input is known, essentially reduces to a linear gate where the key $\mat{K}$ is secret shared and the input $x$ is publicly known.

\paragraph{2PC public-input protocol for \ttwPRF.}
Concretely, for the evaluation of \ttwPRF in the public-input setting, the first round from the distributed protocol can be entirely skipped. The two parties can directly compute shares of $w = \mat{K}x = \sum_{i \in \{1,2\}} \sharei{\mat{K}}x$ locally. This also means that the preprocessing previously required for the $\BLMap$ gate that computed $\mat{K}x$ is no longer necessary. The rest of the evaluation can now proceed as before with both parties first using $\prot_\Convert^{(2,3)}$ to retrieve shares of $w$ over $\Z_3$, and then using $\prot_\LMap^{\mat{B},3}$ to compute shares of the final output $y$.

In total, the evaluation takes a single round and a communication of $m$ bits per party (to reconstruct $\hat{w}$). The only preprocessing required is for the $\prot_{\Convert}^{(2,3)}$ gate, for which each party will be given $m + \log_2{3} \cdot m$ bits. Furthermore, with PRG compression, $\party_2$ will require no extra preprocessing and $\party_1$ can be given only $\log_2{3} \cdot m$ bits.

\fi

%------------------%

\subsection{3-party Distributed Evaluation}
\label{subsec:3party_protocol}

In this section, we provide a 3-party (semi-honest) protocol for computing the \ttwPRF candidate that is secure against one passive corruption and does not require any preprocessing.

\paragraph{Functionality.}
Denote the servers by $\party_1, \party_2$, and $\party_3$. We assume that the servers hold replicated additive shares of the key $\mat{K}$ and the input $x$. The key is assumed to be circulant and can be represented by $k \in \Z_2^n$. Concretely, let $(k_1, k_2, k_3)$ and $(x_1,x_2,x_3)$ be additive shares of $k$ and $x$ respectively. Then, each party $\party_i$ is given $k_j$, $x_j$ with $j \neq i$. At the end of the protocol, $\party_2$ and $\party_3$ should hold $y_2$ and $y_3$ respectively such that $(y_2, y_3)$ is a sharing of the wPRF output $y$.

\paragraph{Protocol details.}
\begin{itemize}
  \item First, the three servers compute additive shares of the linear mapping $\mat{K}{x}$ locally using their replicated shares. Note that this can be locally since for two secret shared values $a = a_1 + a_2 + a_3$ and $b = b_1 + b_2 + b_3$, their product can be computed as $ab = \sum_{1 \leq j,k \leq 3} a_jb_k$. Since each party holds two shares of $a,b$ in a replicated sharing scheme, each term $a_jb_k$ can be computed by at least 1 party. Suppose that the share of $\party_i$ is denoted by $\sharei{\mat{K}x}$.

  \item Now, $\party_1$ samples $\tilde{w} \getsr \Z_2^m$, $r_2 \gets \Z_3^m$, and sets $r_3 = \tilde{w} - r_2 \bmod 3$. In other words $(r_2, r_3)$ is a random $\Z_3$ sharing of $r = \tilde{w}$. $\party_1$ sends $\share{\mat{K}x}^{(1)} + \tilde{w}$ and $r_i$ to $\party_{i \in \{2,3\}}$. At the same time, $\party_2$ and $\party_3$ exchange their shares of $\mat{K}x$. All of this can be done in one round.

  \item At this point, $\party_2$ and $\party_3$ can both compute $\hat{w} = \tilde{w} + \sum_{1\leq i \leq 3} \sharei{\mat{K}x}$. Now, for $i \in \{2,3\}$, $\party_i$ can locally compute $w^*_i \gets \prot_\Convert^{(2,3)}(\hat{w} \mid r_i)$. Finally, $\party_i$ can locally compute its share $y_i$ of the output by running $\prot_\LMap^{\mat{B},3}(\mat{B} \mid w^*_i)$.
\end{itemize}


\paragraph{Cost analysis.}
The protocol requires only 1 round, with two messages sent by $\party_1$ and one message each sent by $\party_2$ and $\party_3$. $\party_1$ sends a total of $2m + 2 \log_2(3)\cdot m$ bits while the other two parties send $m$ bits each. $\party_1$ can also generate a reusable PRG seed and provide it to one of the parties which saves $\log_2(3)\cdot m$ bits of communication.  




%----------------%

\subsection{Oblivious PRF Evaluation in the Preprocessing Model}
\label{subsec:oprf_protocol}
Our distributed evaluation protocols from Section~\ref{subsec:distributed_protocol} can be used directly for semi-honest \textit{oblivious} PRF, or OPRF, evaluation in the preprocessing model. Recall that in the OPRF setting, one party $\party_1$ (called the ``server'') holds the key $\mat{K}$ and the other party $\party_2$ (called the ``client'') holds the input $x$. The goal of the protocol is to have the client learn the output of the PRF for key $\mat{K}$ and input $x$, while the server learns nothing. In the semi-honest setting, both parties can first use the distributed protocol to obtain shares of the PRF output. The server can then send its share to the client so that only the client learns the final output. Such an OPRF protocol would require one extra round over the corresponding distributed PRF protocol. We can however construct much better protocols whose efficiency rivals that of existing DDH-based OPRF protocols. Here, we provide two concrete efficient protocols for evaluating the \ttwPRF candidate (Construction~\ref{construction:23-central-wprf}) in the OPRF setting. 

\paragraph{General structure.} Both protocols take $3$ rounds and involve 2 messages from the server to the client and 1 message from the client to the server. The first server message however, is only required when the key needs to be changed (or re-masked). We call this the key-update phase. Now, when the masked key is already known, our protocols are optimal in the sense that they require only a single message from the client followed by a single message from the server. Since OPRF applications usually involve reusing the same key for many PRF invocations, in such a \textit{multi-input} setting, our protocols are comparable to other 2-round OPRF protocols in literature (e.g., DDH-based). 
\greg{For a real-world use of OPRFs where our construction might be the best option, see \url{https://www.usenix.org/system/files/sec19-thomas.pdf}. 
It uses the DDH-based OPRF for a private set intersection protocol (where the client has one element and the server has a masssive set). }

We detail the two protocols, $\prot^{\textsf{oprf}}_1$ and $\prot^{\textsf{oprf}}_2$, in Sections~\ref{subsec:oprf1} and~\ref{subsec:oprf2} respectively. In Section~\ref{subsec:oprf-comparison}, we compare our OPRF protocols to other common constructions in the literature. Later, in Section~\ref{sec:implementation_and_eval}, we also report on our protocol implementations and compare their performance (both computation and communication) with related work. To foreshadow, a key observation is that in comparison to common OPRF protocols, our protocols are much faster to compute but require preprocessing as well as slightly more communication.


\subsubsection{Oblivious PRF Protocol $\prot^{\textsf{oprf}}_1$}
\label{subsec:oprf1}
Our first OPRF protocol is in spirit similar to the distributed evaluation for the \ttwPRF construction. Since $\mat{K}$ is known to the server, and $x$ is known to the client, both parties do not need to exchange their shares to reconstruct the masked values $\hat{\mat{K}}$ and $\hat{x}$; the party that holds a value can mask it locally and send it to the other party. This allows us to decouple the server's message that masks its PRF key from the rest of the evaluation. To update the key, the server can simply send $\hat{\mat{K}} = \mat{K} + \tilde{\mat{K}}$ to the client. Many PRF evaluations can now be done using the same $\hat{\mat{K}}$.

\paragraph{Preprocessing.} The protocol requires the following preprocessed randomness. The mask $\tilde{\mat{K}}$ is given to the server only when the key-update phase needs to be run. For PRF evaluations, the trusted dealer samples $\tilde{w} \getsr \Z_2^m$ and provides the server and client $\Z_2$ shares of $\tilde{w}$ along with $\Z_3$ shares of $r = \tilde{w}$. Additionally, the dealer also generates an OLE correlation pair $(\tilde{\mat{K}}, \tilde{v})$ and $(\tilde{x}, \hat{v})$ such that $\tilde{\mat{K}} \in \Z_2^{m \times n}$ is a random circulant matrix that is same for all correlations, $\tilde{v} \getsr \Z_2^m$, $\tilde{x} \getsr \Z_2^n$, and $\hat{v} = \tilde{\mat{K}}\tilde{x} + \tilde{v}$. The server is given $(\tilde{\mat{K}}, \tilde{v})$ while the client is given $(\tilde{x}, \hat{v})$. Note that we simply use OLE correlations and do not make use of an actual OLE protocol. In practice, if the key-update phase is run after every $k$ evaluations (where $k$ is known), the OLE correlations for all evaluations can be preprocessed at the beginning. 
% \mahimna{need to write about / point to another section for generating the OLE correlations.}

\paragraph{Protocol details.} Assuming that the masked key $\hat{\mat{K}}$ is known to the client, for an input $x$,  the evaluation protocol now proceeds as follows:
\begin{itemize}
  \item The client computes $\hat{x} = x + \tilde{x}$ and $\share{\hat{w}}^{(2)} = -\mat{\hat{K}}\tilde{x} + \hat{v} + \share{\tilde{w}}^{(2)}$ and sends both $\hat{x}$ and $\share{\hat{w}}^{(2)}$ to the server.

  \item The server first computes $\share{\hat{w}}^{(1)} = \mat{K}\hat{x} - \tilde{v} + \share{\tilde{w}}^{(1)}$, and adds to it the client's share to reconstruct $\hat{w}$. Identical to the distributed protocol, the server now runs $\prot_\Convert^{(2,3)}$ followed by $\prot_\LMap^{\mat{B},3}$ to obtain its share $\share{y}^{(1)}$ of the PRF output. Finally, it sends both $\hat{w}$ and $\share{y}^{(1)}$ to the client.

  \item The client also runs $\prot_\Convert^{(2,3)}$ followed by $\prot_\LMap^{\mat{B},3}$ to obtain its share $\share{y}^{(2)}$ of the PRF output. It can now use the server's share to reconstruct the PRF output $y$.

  % It now runs $\prot_\Convert^{(2,3)}(\hat{w} \mid \share{r}^{(1)})$ to get $\share{w^*}^{(1)}$ (over $\Z_3$) and then $\prot_\LMap^{\mat{B},3}(\mat{B} \mid \share{w^*}^{(1)})$ to obtain its share $\share{y}^{(1)}$ of the PRF output. Finally, it sends both $\hat{w}$ and $\share{y}^{(1)}$ to the client.

  % \item The client now runs $\prot_\Convert^{(2,3)}(\hat{w} \mid \share{r}^{(2)})$ to get $\share{w^*}^{(2)}$ (over $\Z_3$) and then $\prot_\LMap^{\mat{B},3}(\mat{B} \mid \share{w^*}^{(2)})$ to obtain $\share{y}^{(2)}$. Finally, it uses the share received from the server to reconstruct the PRF output $y$ 
\end{itemize}
For evaluating a client input, $\prot^{\textsf{oprf}}_1$ takes 2 rounds and involves a single message in each direction. The client sends $2n$ bits while the server sends $m$ bits and $t$ $\Z_3$ elements. For our parameters ($n=m=256, t=81$), and with proper $\Z_3$ packing, this amounts to roughly $897$ bits of total online communication. To update $\tilde{\mat{K}}$, the server sends a 256-bit message to the client.


\subsubsection{Oblivious PRF Protocol $\prot^{\textsf{oprf}}_2$}
\label{subsec:oprf2}
For the second protocol, the server masks the PRF in a different way; a multiplicative mask is used instead of an additive one. For simplicity, suppose that $n=m$ and that the key $\mat{K}$ is a random full-rank circulant matrix. Then to mask $\mat{K}$, the server computes $\bar{\mat{K}} = \mat{R}\mat{K}$ using a random matrix $\mat{R}$ that is also full-rank and circulant. $\mat{R}$ will be provided as preprocessing to the server, and can be reused for multiple PRF evaluations. The server will send $\bar{\mat{K}}$ to the client in the key-update phase. Note that since the product of two circulant matrices is also circulant, this message is only $n$ bits. Additionally, since the product $\mat{R}\mat{K}$ is essentially a convolution, it can be efficiently computed in $\Theta(n\log n)$ asymptotic runtime using the fast Fourier transform (FFT) algorithm.

\paragraph{Preprocessing.} The protocol requires the following preprocessed randomness. The mask $\mat{R}$ is given to the server only when the key-update phase needs to be run. For PRF evaluations, similar to first protocol, the dealer samples $w \getsr \Z_2^m$ and provides the server and client $\Z_2$ shares of $\tilde{w}$ along with $\Z_3$ shares of $r = \tilde{w}$. Additionally, the dealer gives $\tilde{u} \getsr \Z_2^m$ to the client and $\tilde{v} = \mat{R}^{-1}\tilde{u} + \tilde{w}$ to the server.

\paragraph{Protocol details.} Now, assuming that the masked key $\bar{\mat{K}}$ is known to the client, for an input $x$,  the evaluation protocol now proceeds as follows:
\begin{itemize}
  \item The client computes $\hat{u} = \bar{\mat{K}}x + \tilde{u}$ and sends it to the server.

  \item The server first computes $\mat{R}^{-1}\hat{u} + \tilde{v} = \mat{R}^{-1}(\mat{R}\mat{K}x + \tilde{u}) + (\mat{R}^{-1}\tilde{u} + \tilde{w}) = \hat{w} \mod 2$. Identical to the distributed protocol, the server now runs $\prot_\Convert^{(2,3)}$ followed by $\prot_\LMap^{\mat{B},3}$ to obtain its share $\share{y}^{(1)}$ of the PRF output. Finally, it sends both $\hat{w}$ and $\share{y}^{(1)}$ to the client.

  \item The client also runs $\prot_\Convert^{(2,3)}$ followed by $\prot_\LMap^{\mat{B},3}$ to obtain its share $\share{y}^{(2)}$ of the PRF output. It can now use the server's share to reconstruct the PRF output $y$.
\end{itemize}
For evaluating a client input, $\prot^{\textsf{oprf}}_2$ also takes 2 rounds and involves a single message in each direction. The client sends $n$ bits while the server sends $m$ bits and $t$ $\Z_3$ elements. This is $n$ fewer bits of communication as compared to the first protocol. The key-update phase is slower however, since it involves a convolution rather than a simple vector addition. For our parameters ($n=m=256, t=81$), and with proper $\Z_3$ packing, this amounts to roughly $641$ bits of total online communication. To update $\bar{\mat{K}}$, the server sends a 256-bit message to the client.


\subsubsection{Comparison}
\label{subsec:oprf-comparison}
Here, we compare the concrete efficiency of our protocols with other protocols in literature.
\paragraph{DDH-based OPRF.}
A simple and widely used OPRF is based on the Decision Diffie-Hellman (DDH) assumption. Abstractly, given a cyclic group $\mathbb{G}$ of prime order $q$, consider a PRF $\mathsf{F}$ defined as follows: For key $k \in \keyspace$ and input $x \in \inspace$, define $\mathsf{F}(k,x) = H(x)^k$ where $H:\inspace \to \mathbb{G}$ is a hash function modeled as a random oracle. $\mathsf{F}$ is a secure PRF under the DDH assumption in the random oracle model~\cite{naor1999-oprf}.

The PRF $\mathsf{F}$ leads to a natural 2-party (semi-honest) protocol for oblivious evaluation. Concretely, suppose that the client holds $x$ and the server holds $k$. To evaluate the PRF obliviously, the client initiates the interaction by first sampling a mask $r \getsr \mathbb{Z}_q$ and then sending $a \gets H(x)^r$ to the server. The server responds with $b \gets a^k$. Finally, the client can retrieve the PRF computation as $y \gets b^{r^{-1}}$ where $r^{-1}$ is the multiplicative inverse of $r$ in $\Z_q$. Security of this OPRF protocol has been shown in~\cite{jarecki2014-ddhoprf,jarecki2016-ddhoprf}, assuming the one-more discrete-log assumption~\cite{bellare2003-onemore} (and in the random oracle model).

We instantiate a DDH-based OPRF over the Curve25519 elliptic curve and compare its efficiency to our OPRF constructions. The key takeaway we found was that for both our constructions, the total computation time is smaller than the time it takes for a \textit{single} elliptic curve scalar multiplication. One caveat is that our protocols require preprocessing, as well as slightly higher communication. However, we show that for reasonable network speeds, the overall cost of our protocol is still smaller. We provide more details of this comparison as part of our evaluation in Section~\ref{subsec:performance}.


\paragraph{Other OPRFs.}
Many prior OPRF constructions~\cite{freedman2005-oprf,jarecki2009-oprf} require expensive exponentiations because they are based on algebraic PRFs. This means that we can expect similar performance tradeoffs for our protocols when compared to them (i.e., much faster computation, slightly more communication).~\cite{kolesnikov2016-oprf} provides an efficient batched-OPRF protocol based on OT extension in the preprocessing. While we did not perform with the same setup, based on their performance results, we found that our protocol is substantially more efficient for a single (or a small number of) evaluation, but becomes more comparable in performance as the batch-size increases which is unsurprising considering our protocols are not optimized for the batched evaluation. Recent work~\cite{seres2021-legendre} constructs an OPRF protocol from the Legendre PRF~\cite{damgard1988-legendre}. For 128-bit security, their protocol has a communication cost of $\approx 13$KB which is substantially higher than ours.


%-------------------%
\subsection{Generating the correlated randomness.}
\label{subsec:preprocessing}
While our distributed protocols are primarily built for use in the preprocessing model, in this section we will also show how to generate the preprocessing we require efficiently and without a trusted dealer. We will focus on the 2-party setting specifically. Three of our gate protocols, namely $\prot_\BLMap$, $\prot_\Convert^{(2,3)}$, and $\prot_\Convert^{(3,2)}$, require correlated randomness as preprocessing. In this section, we will show how to efficiently generate the randomness they require.


\subsubsection{Bilinear correlations}
To compute a secure multiplication $\mat{K}x$ where $\mat{K}$ and $x$ are both secret shared, our bilinear gate protocol requires Beaver-style preprocessed shares of the form $(\share{\tilde{\mat{K}}}, \share{\tilde{x}}, \share{\tilde{\mat{K}}\tilde{x}})$. These triples can be compressed using variants of existing PCGs for VOLE / OLE as shown by recent work~\cite{boyle2019-pcg, boyle2020-lpn-pcg}. Using these techniques, $n$ correlations can be generated with $\ll n$ bits of communication.


\subsubsection{$(2,3)$-correlations from OT correlations}
We provide a new technique to generate the correlations needed for the $\prot_\Convert^{(2,3)}$ protocol. The key technique we use is to convert OT correlations to the types of correlations our protocols require. Since prior work~\cite{?} has shown how to efficiently create OT correlations, this implies that the correlations required for our protocols can also be efficiently generated. We start by recalling OT correlations in the 2-party setting. 

\paragraph{1-out-of-2 OT correlation over $\Z_3$.} An OT correlation over $\Z_3$ has the following form: $\party_1$ holds $(z_0, z_1)$ and $\party_2$ holds $(c, z_c)$ where $z_0, z_1 \getsr \Z_3$, $c \in \Z_2$ and $z_c = z_0$ if $c=0$ and $z_c = z_1$ if $c=1$. We refer to $((z_0,z_1), (c, z_c))$ as an OT correlation pair.

\paragraph{Conversion technique.}
Recall that for the $\Z_2 \to \Z_3$ conversion protocol $\prot_{\Convert}^{(2,3)}$, as preprocessing, a dealer provides the parties with shares of a bit-vector both over $\Z_2$ and $\Z_3$. For simplicity, we first consider the correlated randomness for a single element. To convert the sharing for a single bit, the dealer provides the following correlated randomness to the parties: $\party_1$ is given $(w_1, r_1)$ and $\party_2$ is given $(w_2, r_2)$ such that $w_1, w_2 \in \Z_2; r_1, r_2 \in \Z_3$ and $(w_1 + w_2) \bmod 2 = (r_1 + r_2) \bmod 3$. We refer to $((w_1, r_1), (w_2, r_2))$ as a $(2,3)$ correlation pair.

We now show how to convert an OT correlation into a $(2,3)$ correlation. Suppose for now that we have the ability to ``throw'' away OT correlations where $z_0 = z_1$. We will get rid of this assumption later by communicating a single message from $\party_1$ to $\party_2$ which will intuitively detail which OT correlations to discard.

\begin{protocol}
Given a (1-out-of-2) OT correlation $((z_0,z_1), (c, z_c))$ over $\Z_3$ where $z_0 \neq z_1$, to generate a $(2,3)$-correlation, the parties proceed as follows:

\begin{itemize}
  \item $\party_1$ computes
  \[ (w_1, r_1) = 
  \begin{cases} 
      (0, z_0) & \text{if } z_1=z_0-1 \bmod 3 \\
      (1, z_1) & \text{if } z_0=z_1-1 \bmod 3 \\
   \end{cases}
  \]
  \item $\party_2$ computes $(w_2, r_2) = (c, -z_c \bmod 3)$.
\end{itemize}
\label{prot:ot-to-23}
\end{protocol}


\begin{lemma}
  Protocol~\ref{prot:ot-to-23} securely generates a random $(2,3)$-correlation.
\end{lemma}
\begin{proof}
It is easy to see that the secret $w = w_1 + w_2 \bmod 2$ is hidden. Regardless of what $w_2 = c$ is, $w_1$ could be either $0$ or $1$ with equal probability. It is also straightforward to verify that the generated $(2,3)$-correlation is random by iterating through all the possible cases.
\end{proof}
\mahimna{@yuval}

This means that an OT correlation can locally be converted to a $(2,3)$ correlation when $z_0 \neq z_1$. Since $\party_1$ knows these values, it still needs to communicate to $\party_2$ whether to use a given correlation or not. 
For this, $\party_1$ sends a single message which describes the set of instances to consider. Specifically, for a sequence of $k$ OT correlations, $\party_1$ can send a $k$ bit message where each bit signals whether to use the corresponding correlations. 

Therefore, to the obtain $l$ single-element $(2,3)$ correlations necessary for an $x \in \Z_2^l$, on expectation, $1.5l$ OT correlations will be required. Na{\"i}vely, this would require a $1.5l$ length message from $\party_1$ to $\party_2$. This can be easily compressed however, using the binary entropy function $\textsf{H}_b(p)$ which computes the entropy of a Bernoulli process with probability $p$. Specifically, since we expect to throw away $p = 1/3$ fraction of the OT correlations, the message from $\party_1$ to $\party_2$ can be compressed to only $1.5l \cdot \textsf{H}_b(1/3) \approx 1.377l$ bits. Consequently, on expectation, a single $(2,3)$ correlation can be generated using just $1.377$ bits of communication.

As another upshot, this means that the required $(2,3)$ correlations can be generated on the fly even during the online phase. For example, in the \ttwPRF protocol, the $(2,3)$ correlations required can be generated along with the first round of the online protocol without needing them to be given earlier as preprocessing. Note that the number of communication rounds still stays the same.


\subsubsection{$(3,2)$-correlations from OT correlations}

We now show how to convert OT-correlations to the correlations we require for the $\prot_{\Convert}^{(3,2)}$ protocol. For this, we will need 1-out-of-3 OT correlations for 2-bit strings. Formally, in such a correlation, $\party_1$ receives $(z_0, z_1, z_2)$ where each $z_j$ is a 2-bit string, while $\party_2$ receives $(c, z_c)$ where $c \in \Z_3$ and $z_c$ is the corresponding $z_j$ indexed by $j = c$. As before, these OT correlations can also be efficiently generated and compressed using existing work~\cite{??}.
\mahimna{@yuval}

Now, to convert a single $\Z_2$ element to $\Z_3$, our protocol requires the following correlated randomness: $\party_i$ is given $(\tilde{x}_i, u_i, v_i)$ where $\tilde{x}_i \in \Z_3$, $u_i,v_i \in \Z_2$ such that the following holds. Define $\tilde{x} = \tilde{x}_1 + \tilde{x} \bmod 3$, $u = u_1 + u_2 \bmod 2$, and $v = v_1 + v_2 \bmod 2$. Then, $u = \tilde{x} \bmod 2$ and $v = (\tilde{x} + 1 \bmod 3) \bmod 2$. We call this sharing between the two protocol parties a $(3,2)$-correlation pair.

\begin{protocol}
Given a (1-out-of-3) OT-correlation $((z_0,z_1,z_2), (c,z_c))$ for 2-bit strings, to generate a $(3,2)$-correlation from this, the parties proceed as follows:
\begin{itemize}[topsep=0pt]
  \item First, $\party_1$ samples its shares randomly as $\tilde{x}_1 \getsr \Z_3$, $u_1, v_1 \getsr \Z_2$.
  \item Now, for each $j \in \Z_3$, $\party_1$ sets the 2-bit string $s_j$ as follows. Let $w = \tilde{x}_i + j \bmod 3$. Then, $s_j = (u_1 \parallel \neg v_1)$ if $w = 0$; $s_j = (\neg u_1 \parallel v_1)$ if $w = 1$; $s_j = (u_1 \parallel v_1)$ if $w = 2$. Intuitively, $\party_1$ sets the OT tuple to be what $\party_2$'s share would be if it chose that particular index in an OT protocol.
  \item $\party_1$ masks the $s_j$ and sends them to $\party_2$. Specifically, $\party_1$ sends $r_j \gets s_j + z_j$ (where each bit is added modulo 2) for each $j \in \Z_3$.

  \item $\party_2$ sets $\tilde{x}_2 \gets c$, and $u_2 \parallel v_2 \gets r_c$ (i.e., the corresponding 2-bit string $r_c$ sent by $\party_1$ is parsed into $u_2$ and $v_2$)

  \item Finally, for the $(3,2)$-correlation, $\party_i$ takes its share as $(\tilde{x}_i, u_i, v_i)$
  \end{itemize}
\label{prot:ot-to-32}
\end{protocol}
This is less efficient than our protocol to generate a $(2,3)$ correlation and takes 6 bits of communication per instance. Note that the communication is still unidirectional as only $\party_1$ sends a message. Consequently, the $(3,2)$ correlations can also be generated on the fly given OT correlations as part of the first protocol round. 


\begin{lemma}
  Protocol~\ref{prot:ot-to-32} securely generates a random $(3,2)$-correlation.
\end{lemma}
\begin{proof}
Since $\party_1$ generates $\tilde{x}_1, u_1, v_1$ randomly, $[s_0, s_1, s_2] + [(u_1 \parallel v_1), (u_1 \parallel v_1), (u_1 \parallel v_1)]$ is a random cyclic rotation of $[``01", ``10", ``00"]$ where the shift depends on $\tilde{x}_1$. Now, since $\party_1$ masks the $s_j$, its message to $\party_2$ simulates an OT protocol given an OT correlation. Consequently, the security of the OT protocol will directly imply that the message from $\party_1$ to $\party_2$ hides $\tilde{x}_1$. The proof that the generated correlation is random is also straightforward by iterating through all possible cases. 
\end{proof}
\mahimna{@yuval}



\subsection{Table}

\mahimna{Placeholder section for cost table. Will some somewhere else later}


\newcommand{\formula}[1]{{\color{red} #1}}

\begin{table}[h]
{
\centering
\resizebox{\textwidth}{!}{%
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
  \hline
  \multirow{3}{*}{Primitive} & \multirow{3}{*}{Construction} & \multirow{3}{*}{\makecell{Param. \\ $(n,m,t)$}} & \multicolumn{2}{c|}{\makecell{Distributed 2PC \\ (with preprocessing)}} & \makecell{Distributed \\ 3PC} &  \multicolumn{2}{c|}{\makecell{Public-Input 2PC \\ (with preprocessing)}} \\
  \cline{4-8}
  & & & \makecell{Online \\ Comm.} & \makecell{Prepr.} & \makecell{Online \\ Comm.} & \makecell{Online \\ Comm.} & \makecell{Prepr.} \\
  \hline \hline

  \multirow{2}{*}{wPRF} & \makecell{\ttwPRF} & $(256,256,81)$ & $(1536,4,2)$ & $(2348,662)$ & $(1430,4,1)$ & $(512,2,1)$ & $(1324, 406)$ \\
  % & $(3,2)$-wPRF & $\formula{(n,m,t)}$ & $(\formula{4cn+2cm},4,2)$ & & & & $(\formula{2cm},2,1)$ & & \\
  % 2PC 
  % comm = 4cn + 2cm, 
  %preprocessing = (2(2cn+cm+2m), cm + 2m)

  % Public-input
  % Comm = 2cm
  % preprocessing = (2(cm+2m), 2m)

  & LPN-wPRF & $(256,256,128)$ & $(2860,6,3)$ & $(4995,1730)$ & &$(1324,4,2)$ & $(3160,918)$ \\

  \hline

  \multirow{1}{*}{OWF} & \makecell{\ttOWF} & $(128, 452, 81)$ & $(904,2,1)$ & $(2337, 717)$ & $(2525,4,1)$ & - & - \\
  % & \makecell{$(3,2)$-OWF} &  &  &  & & & - & - & - \\
  % & \makecell{LPN-OWF} &  &  &  & & & - & - & - \\

  \hline

  PRG & LPN-PRG & $(128,512,256)$ & $(1880, 4, 2)$ & $(4334, 1227)$ & & - & -  \\
  % 2PC 
  % Communication (2n+2cm) 
  % Preprocessing (5.17n + 7.17m, 1.585n + 2m)
  \hline
  \end{tabular}
}
\caption{Concrete MPC costs for our winning candidate constructions in three settings (Distributed 2PC (with preprocessing), 3PC, and Public-input 2PC) using our proposed parameters. For the distributed 2PC and the public-input 2PC settings, we provide the total online communication (bits, messages, rounds) and the preprocessing required in bits (without compression, with compression). For the compressed size of the preprocessing, we do not include values that can be reused (e.g., PRG seeds). For the distributed 3PC setting, we provide the total online communication cost (bits, messages, rounds) and do not include the reusable PRG seeds.}
}
\end{table}
